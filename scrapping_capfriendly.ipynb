{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Intro",
   "metadata": {
    "is_collapsed": false,
    "cell_id": "ada6bf76f3414648b4a22120a6bd2b50",
    "tags": [],
    "formattedRanges": [],
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "markdown",
   "source": "! NOTE BEFORE USING THIS NOTEBOOK. If you know anything about CapFriendly API, please DM me, I will delete this notebook as it is much more polite to retrieve data using API. Using scrapper is the last case scenario.",
   "metadata": {
    "is_collapsed": false,
    "cell_id": "c458b7f6-8b06-4cf4-8a34-d429388c5ff7",
    "tags": [],
    "formattedRanges": [],
    "deepnote_cell_type": "text-cell-p"
   }
  },
  {
   "cell_type": "markdown",
   "source": "We will get the players' stats and salaries by going through this notebook.",
   "metadata": {
    "is_collapsed": false,
    "cell_id": "f4229320-fe47-44e3-be5d-e108b4c9e90f",
    "tags": [],
    "formattedRanges": [],
    "deepnote_cell_type": "text-cell-p"
   }
  },
  {
   "cell_type": "markdown",
   "source": "At first, we need to set all needed filters and conditions on players. Then we will use the resulting URL to get data.",
   "metadata": {
    "formattedRanges": [],
    "is_collapsed": false,
    "cell_id": "ec897397-de13-4089-9bd7-47f3e828d394",
    "tags": [],
    "deepnote_cell_type": "text-cell-p"
   }
  },
  {
   "cell_type": "markdown",
   "source": "For example, I will scrap all the players through last 5 seasons. ",
   "metadata": {
    "formattedRanges": [],
    "is_collapsed": false,
    "cell_id": "2dacce521d914268867e2b3fcfe2899d",
    "tags": [],
    "deepnote_cell_type": "text-cell-p"
   }
  },
  {
   "cell_type": "markdown",
   "source": "As I need data season-by-season I am going to start from the last season to the earliest I need.",
   "metadata": {
    "formattedRanges": [],
    "is_collapsed": false,
    "cell_id": "f1c3a63adaee4cf98cc3633667c09062",
    "tags": [],
    "deepnote_cell_type": "text-cell-p"
   }
  },
  {
   "cell_type": "markdown",
   "source": "This link will allow me to download data for the 2020-2021 season with all parameters and columns specified.",
   "metadata": {
    "is_collapsed": false,
    "cell_id": "d220fa9b-ffc7-48d9-a467-9ae53f38b1aa",
    "tags": [],
    "formattedRanges": [
     {
      "type": "link",
      "url": "https://www.capfriendly.com/browse/active/2021?stats-season=2022&display=birthday,country,weightkg,heightcm,draft,slide-candidate,signing-status,expiry-year,performance-bonus,caphit-percent,aav,length,minors-salary,base-salary,skater-individual-advanced-stats,skater-on-ice-advanced-stats,goalie-advanced-stats,type,signing-age,signing-date,arbitration,extension",
      "fromCodePoint": 0,
      "toCodePoint": 108,
      "ranges": []
     }
    ],
    "deepnote_cell_type": "text-cell-p"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Let's do some coding now.",
   "metadata": {
    "formattedRanges": [],
    "is_collapsed": false,
    "cell_id": "054210b420cd40b7891f368e599b2426",
    "tags": [],
    "deepnote_cell_type": "text-cell-p"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Scrapping the main table",
   "metadata": {
    "is_collapsed": false,
    "cell_id": "8a9825baf791452da3fff3e7d7b25797",
    "tags": [],
    "formattedRanges": [],
    "deepnote_cell_type": "text-cell-h2"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "e24af85c06a146aca5fff3c9568de60b",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a990b347",
    "execution_start": 1666867481280,
    "execution_millis": 2,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 148
   },
   "source": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport time\nimport logging",
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# parse a needed url\nurl_v2 = \"https://www.capfriendly.com/browse/active/2021?stats-season=2021&display=birthday,country,weightkg,heightcm,draft,slide-candidate,signing-status,expiry-year,performance-bonus,caphit-percent,aav,length,minors-salary,base-salary,skater-individual-advanced-stats,skater-on-ice-advanced-stats,goalie-advanced-stats,type,signing-age,signing-date,arbitration,extension&limits=gp-5-90\"\n\nreq = requests.get(url_v2)\nsoup = BeautifulSoup(req.content)  # make a soup of html & css from the web page",
   "metadata": {
    "cell_id": "03b4bba344aa41c4916fbf1183e4b290",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5d72dc05",
    "execution_start": 1666867482176,
    "execution_millis": 227,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 153
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "df = pd.read_html(url_v2, header=0, index_col = 0, na_values=[\"-\"])[0]",
   "metadata": {
    "cell_id": "98e080d79ed84e939cca8709eed02b0c",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "57bf627",
    "execution_start": 1666867484214,
    "execution_millis": 108,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 76
   },
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": "df.shape",
   "metadata": {
    "cell_id": "5b97d9f190694c6a85a80f908a406104",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "14f60b8f",
    "execution_start": 1666867485216,
    "execution_millis": 5,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 112.1875,
    "deepnote_output_heights": [
     20.1875
    ]
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 28,
     "data": {
      "text/plain": "(50, 65)"
     },
     "metadata": {}
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": "As we see above, only data on 50 players has been retrieved. ",
   "metadata": {
    "is_collapsed": false,
    "cell_id": "d36550fea15e47e488174cd0643da76e",
    "tags": [],
    "formattedRanges": [],
    "deepnote_cell_type": "text-cell-p"
   }
  },
  {
   "cell_type": "markdown",
   "source": "How do we parse other pages, if there are more than 50 players in our url?",
   "metadata": {
    "is_collapsed": false,
    "cell_id": "43fbe1cb-6241-43a9-9008-7f2a5ccccd80",
    "tags": [],
    "formattedRanges": [],
    "deepnote_cell_type": "text-cell-p"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Scrapping multiple pages of main table",
   "metadata": {
    "is_collapsed": false,
    "cell_id": "73aa93d0afad45dda4d3828dd130ba29",
    "tags": [],
    "formattedRanges": [],
    "deepnote_cell_type": "text-cell-h3"
   }
  },
  {
   "cell_type": "code",
   "source": "info_about_lists = soup.find_all(\"a\", {\"class\": \"whi pagin_r\"})  # via devtools we find the element that allows to switch between pages of data",
   "metadata": {
    "cell_id": "b670a6d662e74e0ea5780da1c2060fc8",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "db632713",
    "execution_start": 1666867691323,
    "execution_millis": 0,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print(info_about_lists)  # all links to other pages of data",
   "metadata": {
    "cell_id": "0e19437f50484407b8ad443f88d8a0c7",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1da76a19",
    "execution_start": 1666867694149,
    "execution_millis": 4,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 111.1875,
    "deepnote_output_heights": [
     58.578125
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "[<a class=\"whi pagin_r\" data-val=\"2\" href=\"/browse/?p=2\">2</a>, <a class=\"whi pagin_r\" data-val=\"3\" href=\"/browse/?p=3\">3</a>, <a class=\"whi pagin_r\" data-val=\"18\" href=\"/browse/?p=18\">Last</a>]\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "source": "last_list_num = int(info_about_lists[-1][\"data-val\"])  # take the last number of page from date-val so we now how many values were selected for us",
   "metadata": {
    "cell_id": "8660fb0ddeb04185a19bd782c71e31b7",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4aa1259",
    "execution_start": 1666867698320,
    "execution_millis": 2,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "source": "print(last_list_num)  # check that 18th is last page number we got",
   "metadata": {
    "cell_id": "8ee693f2af0340d2955e6cc2c263a394",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8f0ba18e",
    "execution_start": 1666867699343,
    "execution_millis": 6,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 106.6875
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "18\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": "Now we can use for loop to parse all the data we have on multiple pages. ",
   "metadata": {
    "is_collapsed": false,
    "cell_id": "e73ad4d1bba84dc2acd4f393b65eda1d",
    "tags": [],
    "formattedRanges": [],
    "deepnote_cell_type": "text-cell-p"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Final Block of Code",
   "metadata": {
    "is_collapsed": false,
    "cell_id": "86d68dc85072424995834ef9d15d037d",
    "tags": [],
    "formattedRanges": [],
    "deepnote_cell_type": "text-cell-h3"
   }
  },
  {
   "cell_type": "code",
   "source": "req = requests.get(url_v2)\nsoup = BeautifulSoup(req.content)  # make a soup of html & css from the web page\n\ninfo_about_lists = soup.find_all(\"a\", {\"class\": \"whi pagin_r\"})  # via devtools we find the element that allows to switch between pages of data\nlast_list_num = int(info_about_lists[-1][\"data-val\"])  # take the last number of page from date-val so we now how many values were selected for us\n\npages_dfs = []\n\nfor page_num in range(1, last_list_num + 1):\n\n        print(f\"Start scapring page {page_num}\")\n\n        time.sleep(1)  # let the page download the results\n\n        url = url_start + f\"&pg={page_num}\"  # we parse the needed page by adding a parameter for url\n        df = pd.read_html(url, header=0, index_col = 0, na_values=[\"-\"])[0]\n\n        df = df.reset_index()  # to have player name as a separate column\n\n        print(df.shape[0], f\"rows were retrieved from page number {page_num}\")\n\n        pages_dfs.append(df)\n\n\nresult_df = pd.concat(pages_dfs)",
   "metadata": {
    "cell_id": "0007e84a12e9427fbdd05b9696250298",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b1d230e",
    "execution_start": 1666868070603,
    "execution_millis": 20405,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1133
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Start scapring page 1\n50 rows were retrieved from page number 1\nStart scapring page 2\n50 rows were retrieved from page number 2\nStart scapring page 3\n50 rows were retrieved from page number 3\nStart scapring page 4\n50 rows were retrieved from page number 4\nStart scapring page 5\n50 rows were retrieved from page number 5\nStart scapring page 6\n50 rows were retrieved from page number 6\nStart scapring page 7\n50 rows were retrieved from page number 7\nStart scapring page 8\n50 rows were retrieved from page number 8\nStart scapring page 9\n50 rows were retrieved from page number 9\nStart scapring page 10\n50 rows were retrieved from page number 10\nStart scapring page 11\n50 rows were retrieved from page number 11\nStart scapring page 12\n50 rows were retrieved from page number 12\nStart scapring page 13\n50 rows were retrieved from page number 13\nStart scapring page 14\n50 rows were retrieved from page number 14\nStart scapring page 15\n50 rows were retrieved from page number 15\nStart scapring page 16\n50 rows were retrieved from page number 16\nStart scapring page 17\n50 rows were retrieved from page number 17\nStart scapring page 18\n44 rows were retrieved from page number 18\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "source": "Now let's add an extension to code to download caphits data of multiple seasons into one dataframe.",
   "metadata": {
    "is_collapsed": false,
    "cell_id": "9a04482c04824ba19cee17dedc221dea",
    "tags": [],
    "formattedRanges": [],
    "deepnote_cell_type": "text-cell-p"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Scrapping caphits data season by season",
   "metadata": {
    "is_collapsed": false,
    "cell_id": "f74e7dfe66b54c93900c11f5e091a1c4",
    "tags": [],
    "formattedRanges": [],
    "deepnote_cell_type": "text-cell-h2"
   }
  },
  {
   "cell_type": "code",
   "source": "seasons_dfs = []  # multiple seasons will be stored as different dataframes first\n\nfor year in range (2016, 2022):\n\n    url_start = f\"https://www.capfriendly.com/browse/active/{year}?stats-season={year}&display=birthday,country,weightkg,heightcm,draft,slide-candidate,signing-status,expiry-year,performance-bonus,caphit-percent,aav,length,minors-salary,base-salary,skater-individual-advanced-stats,skater-on-ice-advanced-stats,goalie-advanced-stats,type,signing-age,signing-date,arbitration,extension&limits=gp-5-90\"\n\n    req = requests.get(url_start)\n\n    soup = BeautifulSoup(req.content)\n\n    info_about_lists = soup.find_all(\"a\", {\"class\": \"whi pagin_r\"})\n    last_list_num = int(info_about_lists[-1][\"data-val\"])  # take the last number of page from date-val\n\n    time.sleep(3)  # let's scrapp politely, \n\n    pages_dfs = []\n\n    for page_num in range(1, last_list_num + 1):\n\n        logging.info(f\"Start season {year} scapring page {page_num}\")\n\n        time.sleep(2)  # let the page download the results\n\n        url = url_start + f\"&pg={page_num}\"\n        df = pd.read_html(url, header=0, index_col = 0, na_values=[\"-\"])[0]\n\n        pages_dfs.append(df)\n\n    one_season_df = pd.concat(pages_dfs)\n\n    one_season_df = one_season_df.reset_index()\n\n    one_season_df['season_start_year'] = year\n\n    seasons_dfs.append(one_season_df)\n\ntotal_df = pd.concat(seasons_dfs)\n",
   "metadata": {
    "cell_id": "60a1e9c001df48c7937e55698a93a151",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "db549b4",
    "execution_start": 1666869204931,
    "execution_millis": 231208,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1367
   },
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "cell_id": "b3ac8fe4ed3348c0bccecf569e3bdb58",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 61
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=fb97efa2-d417-46e7-813c-0372ce0dd7f6' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {},
  "deepnote_notebook_id": "a2e9e17d-48b4-4596-8751-ad9e22843846",
  "deepnote_execution_queue": []
 }
}